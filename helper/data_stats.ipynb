{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_trigger = [[896, 76, 21], [ 70, 828, 57], [13, 76, 907]]\n",
    "universal_trigger = [[256, 327, 410], [6, 246, 703], [6, 157, 833]]\n",
    "random_trigger = [[707, 217, 69], [57, 802, 96], [14, 70, 912]]\n",
    "\n",
    "def get_accuracy(matrix):\n",
    "    for ground_truth in range(3):\n",
    "        scores = [round(score * 100 / sum(matrix[ground_truth]), 2) for score in matrix[ground_truth]]\n",
    "        print(f\"Ground truth: {ground_truth}, Scores: {scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: 0, Scores: [90.23, 7.65, 2.11]\n",
      "Ground truth: 1, Scores: [7.33, 86.7, 5.97]\n",
      "Ground truth: 2, Scores: [1.31, 7.63, 91.06]\n",
      "Ground truth: 0, Scores: [25.78, 32.93, 41.29]\n",
      "Ground truth: 1, Scores: [0.63, 25.76, 73.61]\n",
      "Ground truth: 2, Scores: [0.6, 15.76, 83.63]\n",
      "Ground truth: 0, Scores: [71.2, 21.85, 6.95]\n",
      "Ground truth: 1, Scores: [5.97, 83.98, 10.05]\n",
      "Ground truth: 2, Scores: [1.41, 7.03, 91.57]\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(no_trigger)\n",
    "get_accuracy(universal_trigger)\n",
    "get_accuracy(random_trigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground Truth    Data                         E% , N% , C%           \n",
    "Entailment      Validation subset           90.23, 7.65, 2.11\n",
    "                Challenge Set I             25.78, 32.93, 41.29\n",
    "                Challenge Set II            71.2, 21.85, 6.95\n",
    "\n",
    "Neutral         Validation subset           7.33, 86.7, 5.97\n",
    "                Challenge Set I             0.63, 25.76, 73.61\n",
    "                Challenge Set II            5.97, 83.98, 10.05\n",
    "\n",
    "Contradiction   Validation subset           1.31, 7.63, 91.06\n",
    "                Challenge Set I             0.6, 15.76, 83.63\n",
    "                Challenge Set II            1.41, 7.03, 91.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd19ece62558461598b0acac9c6af1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f4eb96ca6f4d939f483f5c454b644f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b96e4d3b6a74b6e96e8c6f6242a8507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/412k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001983cd4ec4d4f9548ec73b85c12c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/413k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7782422fcd524fec99f2527db0652ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dfd7372dad4158bbdb5b389bb7fefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0851d73feb2b48b1af5d018b8b8810c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b4e90ad8e34f469970356e5c415857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f25c6aad4845b49f93b3c98edf9b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/550152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_snli_data():\n",
    "    dataset = load_dataset('snli', split='train')\n",
    "    return dataset\n",
    "\n",
    "def get_word_and_class_counts(dataset=load_snli_data()):\n",
    "    word_counts = defaultdict(lambda: defaultdict(int))\n",
    "    class_counts = Counter()\n",
    "    total_words = 0\n",
    "\n",
    "    for example in tqdm(dataset):\n",
    "        hypothesis = example['hypothesis'].split()\n",
    "        label = example['label']\n",
    "        if label == -1:  # Skip examples with no label\n",
    "            continue\n",
    "        class_counts[label] += 1\n",
    "        for word in hypothesis:\n",
    "            word_counts[word][label] += 1\n",
    "            total_words += 1\n",
    "\n",
    "    return word_counts, class_counts, total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 550152/550152 [00:17<00:00, 30881.87it/s]\n"
     ]
    }
   ],
   "source": [
    "word_counts, _, _ = get_word_and_class_counts()\n",
    "\n",
    "universal_triggers = {\n",
    "    0: ['nobody', 'no', 'whatsoever', 'excuse', 'unfairly'],\n",
    "    1: ['cats', 'monkeys', 'crocodiles', 'elephants', 'cat'],\n",
    "    2: ['joyously', 'celebrating', 'motivational', 'contacting', 'anxiously']\n",
    "}\n",
    "\n",
    "random_triggers = {\n",
    "    0: ['diners', 'sense', 'emerge', 'hands', 'refuge'], \n",
    "    1: ['road', 'elders', 'brick', 'mass', 'bicyclists'] ,\n",
    "    2: ['remain', 'rose', 'towns', 'flashing', 'lip']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nobody 2 0.96\n",
      "no 2 0.83\n",
      "whatsoever 2 1.0\n",
      "excuse 1 1.0\n",
      "unfairly 1 1.0\n",
      "cats 2 0.96\n",
      "monkeys 2 0.87\n",
      "crocodiles 2 1.0\n",
      "elephants 2 0.62\n",
      "cat 2 0.85\n",
      "joyously 1 1.0\n",
      "celebrating 1 0.79\n",
      "motivational 1 0.93\n",
      "contacting 1 0.8\n",
      "anxiously 1 0.86\n",
      "\n",
      "diners 1 0.47\n",
      "sense 1 0.41\n",
      "emerge 1 0.57\n",
      "hands 2 0.38\n",
      "refuge 1 1.0\n",
      "road 1 0.4\n",
      "elders 1 0.5\n",
      "brick 1 0.39\n",
      "mass 0 0.38\n",
      "bicyclists 1 0.37\n",
      "remain 1 0.62\n",
      "rose 1 0.59\n",
      "towns 1 0.6\n",
      "flashing 1 0.5\n",
      "lip 1 0.5\n"
     ]
    }
   ],
   "source": [
    "def majority_class_and_correlation(trigger):\n",
    "    # Fetch the trigger words across all classes\n",
    "    trigger_words = []\n",
    "    for label in trigger:\n",
    "        trigger_words.extend(trigger[label])\n",
    "    # Fetch the counts of each trigger word across all classes\n",
    "    trigger_counts = {}\n",
    "    for word in trigger_words:\n",
    "        dummy = [word_counts[word][lbl] for lbl in range(3)]\n",
    "        trigger_counts[word] = [round(word_counts[word][lbl] /sum(dummy), 2) for lbl in range(3)]\n",
    "        max_idx = dummy.index(max(dummy))\n",
    "        print(f\"{word} {max_idx} {trigger_counts[word][max_idx]}\")\n",
    "    # print(trigger_counts)\n",
    "\n",
    "majority_class_and_correlation(universal_triggers)\n",
    "print(\"\")\n",
    "majority_class_and_correlation(random_triggers)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal       class  score       Random   class   score\n",
    "\n",
    "nobody            2    0.96        diners     1      0.47\n",
    "no                2    0.83        sense      1      0.41\n",
    "whatsoever        2    1.0         emerge     1      0.57\n",
    "excuse            1    1.0         hands      2      0.38\n",
    "unfairly          1    1.0         refuge     1      1.0\n",
    "cats              2    0.96        road       1      0.4\n",
    "monkeys           2    0.87        elders     1      0.5\n",
    "crocodiles        2    1.0         brick      1      0.39\n",
    "elephants         2    0.62        mass       0      0.38\n",
    "cat               2    0.85        bicyclists 1      0.37\n",
    "joyously          1    1.0         remain     1      0.62\n",
    "celebrating       1    0.79        rose       1      0.59\n",
    "motivational      1    0.93        towns      1      0.6\n",
    "contacting        1    0.8         flashing   1      0.5\n",
    "anxiously         1    0.86        lip        1      0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Universal                       Random\n",
    "                Trigger        class  score       Trigger   class   score\n",
    "\n",
    "Entailment      nobody            2    0.96        diners     1      0.47\n",
    "                no                2    0.83        hands      2      0.38\n",
    "\n",
    "Neutral         cats              2    0.96        road       1      0.4\n",
    "                cat               2    0.85        mass       0      0.38\n",
    "\n",
    "Contradiction   joyously          1    1.0         remain     1      0.62\n",
    "                celebrating       1    0.79        rose       1      0.59\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
